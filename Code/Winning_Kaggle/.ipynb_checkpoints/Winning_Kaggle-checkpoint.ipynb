{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle competitions process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore train data\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read train data\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Look at the shape of the data\n",
    "print('Train shape:', train.shape)\n",
    "\n",
    "# Look at the head() of the data\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore test data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the test data\n",
    "test = pd.read_csv('test.csv')\n",
    "# Print train and test columns\n",
    "print('Train columns:', train.columns.tolist())\n",
    "print('Test columns:', test.columns.tolist())\n",
    "\n",
    "# Read the sample submission file\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Look at the head() of the sample submission\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Read the train data\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Create a Random Forest object\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Train a model\n",
    "rf.fit(X=train[['store', 'item']], y=train['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a submission\n",
    "\n",
    "# Read test and sample submission data\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Show the head() of the sample_submission\n",
    "print(sample_submission.head())\n",
    "\n",
    "# Get predictions for the test set\n",
    "test['sales'] = rf.predict(test[['store', 'item']])\n",
    "\n",
    "# Write test predictions using the sample_submission format\n",
    "test[['id', 'sales']].to_csv('kaggle_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What model is overfitting?\n",
    "Let's say you've trained 4 different models and calculated a metric for both train and validation data sets. For example, the metric is Mean Squared Error (the lower its value the better). Train and validation metrics for all the models are presented in the table below.\n",
    "\n",
    "Please, select the model that overfits to train data.\n",
    "\n",
    "Model\tTrain MSE\tValidation MSE\n",
    "Model 1\t2.35\t2.46\n",
    "Model 2\t2.20\t2.15\n",
    "Model 3\t2.10\t2.14\n",
    "Model 4\t1.90\t2.35\n",
    "\n",
    "--> Model 4\n",
    "Note: Model 4 has considerably lower train MSE compared to other models. However, validation MSE started growing again.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost models\n",
    "\n",
    "# Set the maximum depth to 2. Then hit Submit Answer button to train the first model.\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 2,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_2 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Now, set the maximum depth to 8. Then hit Submit Answer button to train the second model.\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 8,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_8 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Finally, set the maximum depth to 15. Then hit Submit Answer button to train the third model.\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 15,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_15 = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore overfitting XGBoost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']])\n",
    "dtest = xgb.DMatrix(data=test[['store', 'item']])\n",
    "\n",
    "# For each of 3 trained models\n",
    "for model in [xg_depth_2, xg_depth_8, xg_depth_15]:\n",
    "    # Make predictions\n",
    "    train_pred = model.predict(dtrain)     \n",
    "    test_pred = model.predict(dtest)          \n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_train = mean_squared_error(train['sales'], train_pred)                  \n",
    "    mse_test = mean_squared_error(test['sales'], test_pred)\n",
    "    print('MSE Train: {:.3f}. MSE Test: {:.3f}'.format(mse_train, mse_test))\n",
    "    \n",
    "\"\"\"\n",
    "MSE Train: 631.275. MSE Test: 558.522\n",
    "MSE Train: 183.771. MSE Test: 337.337\n",
    "MSE Train: 134.984. MSE Test: 355.534\n",
    "\n",
    "So, you see that the third model with depth 15 is already overfitting. \n",
    "It has considerably lower train error compared to the second model, however test error is higher. \n",
    "Be aware of overfitting and move on to the next chapter to know how to beat it!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dive into the Competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Understand the problem type\n",
    "As you've just seen, the first step of the solution workflow is to skim through the problem statement. Your goal now is to determine data types available as well as the problem type for the Avito Demand Prediction Challenge. The evaluation metric in this competition is the Root Mean Squared Error. The problem definition is presented below.\n",
    "\n",
    "In this Kaggle competition, Avito is challenging you to predict demand for an online advertisement based on its full description (price, title, images, etc.), its context (geo position, similar ads already posted) and historical demand for similar ads in the past.\n",
    "\n",
    "What problem type are you facing, and what data do you have at your disposal?\n",
    "\n",
    "--> This is a regression problem with tabular, time series, image and text data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a competition metric\n",
    "\n",
    "# Using numpy, define MSE metric. As a function input, you're given true y_true and predicted y_pred arrays.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import MSE from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define your own MSE function\n",
    "def own_mse(y_true, y_pred):\n",
    "  \t# Raise differences to the power of 2\n",
    "    squares = np.power(y_true - y_pred, 2)\n",
    "    # Find mean over all observations\n",
    "    err = np.mean(squares)\n",
    "    return err\n",
    "\n",
    "print('Sklearn MSE: {:.5f}. '.format(mean_squared_error(y_regression_true, y_regression_pred)))\n",
    "print('Your MSE: {:.5f}. '.format(own_mse(y_regression_true, y_regression_pred)))\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Using numpy, define LogLoss metric. As input, you're given true class y_true and probability predicted prob_pred.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import log_loss from sklearn\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Define your own LogLoss function\n",
    "def own_logloss(y_true, prob_pred):\n",
    "  \t# Find loss for each observation\n",
    "    terms = y_true * np.log(prob_pred) + (1 - y_true) * np.log(1 - prob_pred)\n",
    "    # Find mean over all observations\n",
    "    err = np.mean(terms) \n",
    "    return -err\n",
    "\n",
    "print('Sklearn LogLoss: {:.5f}'.format(log_loss(y_classification_true, y_classification_pred)))\n",
    "print('Your LogLoss: {:.5f}'.format(own_logloss(y_classification_true, y_classification_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA statistics\n",
    "\n",
    "# Shapes of train and test data\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "\n",
    "# Train head()\n",
    "print(train.head())\n",
    "\n",
    "# Describe the target variable\n",
    "print(train.fare_amount.describe())\n",
    "\n",
    "# Train distribution of passengers within rides\n",
    "print(train.passenger_count.value_counts())\n",
    "\n",
    "\"\"\"\n",
    "Train shape: (20000, 8)\n",
    "Test shape: (9914, 7)\n",
    "   id  fare_amount          pickup_datetime  pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count\n",
    "0   0          4.5  2009-06-15 17:26:21 UTC        -73.844311        40.721319         -73.841610         40.712278                1\n",
    "1   1         16.9  2010-01-05 16:52:16 UTC        -74.016048        40.711303         -73.979268         40.782004                1\n",
    "2   2          5.7  2011-08-18 00:35:00 UTC        -73.982738        40.761270         -73.991242         40.750562                2\n",
    "3   3          7.7  2012-04-21 04:30:42 UTC        -73.987130        40.733143         -73.991567         40.758092                1\n",
    "4   4          5.3  2010-03-09 07:51:00 UTC        -73.968095        40.768008         -73.956655         40.783762                1\n",
    "count    20000.000000\n",
    "mean        11.303321\n",
    "std          9.541637\n",
    "min         -3.000000\n",
    "25%          6.000000\n",
    "50%          8.500000\n",
    "75%         12.500000\n",
    "max        180.000000\n",
    "Name: fare_amount, dtype: float64\n",
    "1    13999\n",
    "2     2912\n",
    "5     1327\n",
    "3      860\n",
    "4      420\n",
    "6      407\n",
    "0       75\n",
    "Name: passenger_count, dtype: int64\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA plots I\n",
    "\n",
    "def haversine_distance(train):\n",
    "    \n",
    "    data = [train]\n",
    "    lat1, long1, lat2, long2 = 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'\n",
    "    \n",
    "    for i in data:\n",
    "        R = 6371  #radius of earth in kilometers\n",
    "        #R = 3959 #radius of earth in miles\n",
    "        phi1 = np.radians(i[lat1])\n",
    "        phi2 = np.radians(i[lat2])\n",
    "    \n",
    "        delta_phi = np.radians(i[lat2]-i[lat1])\n",
    "        delta_lambda = np.radians(i[long2]-i[long1])\n",
    "    \n",
    "        #a = sin²((φB - φA)/2) + cos φA . cos φB . sin²((λB - λA)/2)\n",
    "        a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2\n",
    "    \n",
    "        #c = 2 * atan2( √a, √(1−a) )\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "        #d = R*c\n",
    "        d = (R * c) #in kilometers\n",
    "        \n",
    "    return d\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Calculate the ride distance\n",
    "train['distance_km'] = haversine_distance(train)\n",
    "\n",
    "# Draw a scatterplot\n",
    "plt.scatter(x=train['fare_amount'], y=train['distance_km'], alpha=0.5)\n",
    "plt.xlabel('Fare amount')\n",
    "plt.ylabel('Distance, km')\n",
    "plt.title('Fare amount based on the distance')\n",
    "\n",
    "# Limit on the distance\n",
    "plt.ylim(0, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA plots II\n",
    "\n",
    "# Create hour feature\n",
    "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n",
    "train['hour'] = train.pickup_datetime.dt.hour\n",
    "\n",
    "# Find median fare_amount for each hour\n",
    "hour_price = train.groupby('hour', as_index=False)['fare_amount'].median()\n",
    "\n",
    "# Plot the line plot\n",
    "plt.plot(hour_price['hour'], hour_price['fare_amount'], marker='o')\n",
    "plt.xlabel('Hour of the day')\n",
    "plt.ylabel('Median fare amount')\n",
    "plt.title('Fare amount based on day time')\n",
    "plt.xticks(range(24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross-validation\n",
    "\n",
    "# Import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "# Loop through each split\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Obtain training and testing folds\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    print('Fold: {}'.format(fold))\n",
    "    print('CV train shape: {}'.format(cv_train.shape))\n",
    "    print('Medium interest listings in CV train: {}\\n'.format(sum(cv_train.interest_level == 'medium')))\n",
    "    fold += 1\n",
    "    \n",
    "\"\"\"\n",
    "Fold: 0\n",
    "CV train shape: (666, 9)\n",
    "Medium interest listings in CV train: 175\n",
    "\n",
    "Fold: 1\n",
    "CV train shape: (667, 9)\n",
    "Medium interest listings in CV train: 165\n",
    "\n",
    "Fold: 2\n",
    "CV train shape: (667, 9)\n",
    "Medium interest listings in CV train: 162\n",
    "\n",
    "So, we see that the number of observations in each fold is almost uniform. \n",
    "It means that we've just splitted the train data into 3 equal folds. \n",
    "However, if we look at the number of medium-interest listings, \n",
    "it's varying from 162 to 175 from one fold to another. To make them uniform among the folds, let's use Stratified K-fold!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-fold\n",
    "\n",
    "# Import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "str_kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "# Loop through each split\n",
    "fold = 0\n",
    "for train_index, test_index in str_kf.split(train, train['interest_level']):\n",
    "    # Obtain training and testing folds\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    print('Fold: {}'.format(fold))\n",
    "    print('CV train shape: {}'.format(cv_train.shape))\n",
    "    print('Medium interest listings in CV train: {}\\n'.format(sum(cv_train.interest_level == 'medium')))\n",
    "    fold += 1\n",
    "    \n",
    "\"\"\"\n",
    "Fold: 0\n",
    "CV train shape: (666, 9)\n",
    "Medium interest listings in CV train: 167\n",
    "\n",
    "Fold: 1\n",
    "CV train shape: (666, 9)\n",
    "Medium interest listings in CV train: 167\n",
    "\n",
    "Fold: 2\n",
    "CV train shape: (668, 9)\n",
    "Medium interest listings in CV train: 168\n",
    "\n",
    "Now you see that both size and target distribution are the same among the folds.\n",
    "The general rule is to prefer Stratified K-Fold over usual K-Fold in any classification problem.\n",
    "Move to the next lesson to learn about other cross-validation strategies!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time K-fold\n",
    "\n",
    "# Create TimeSeriesSplit object\n",
    "time_kfold = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Sort train data by date\n",
    "train = train.sort_values('date')\n",
    "\n",
    "# Iterate through each split\n",
    "fold = 0\n",
    "for train_index, test_index in time_kfold.split(train):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "    print('Fold :', fold)\n",
    "    print('Train date range: from {} to {}'.format(cv_train.date.min(), cv_train.date.max()))\n",
    "    print('Test date range: from {} to {}\\n'.format(cv_test.date.min(), cv_test.date.max()))\n",
    "    fold += 1\n",
    "    \n",
    "\"\"\"\n",
    "Fold : 0\n",
    "Train date range: from 2017-12-01 to 2017-12-08\n",
    "Test date range: from 2017-12-08 to 2017-12-16\n",
    "\n",
    "Fold : 1\n",
    "Train date range: from 2017-12-01 to 2017-12-16\n",
    "Test date range: from 2017-12-16 to 2017-12-24\n",
    "\n",
    "Fold : 2\n",
    "Train date range: from 2017-12-01 to 2017-12-24\n",
    "Test date range: from 2017-12-24 to 2017-12-31\n",
    "\n",
    "You've applied time K-fold cross-validation strategy for the demand forecasting. Look at the output. \n",
    "It works as expected, training only on the past data and predicting the future. \n",
    "Progress to the next exercise to evaluate different models!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall validation score\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# Sort train data by date\n",
    "train = train.sort_values('date')\n",
    "\n",
    "# Initialize 3-fold time cross-validation\n",
    "kf = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Get MSE scores for each cross-validation split\n",
    "mse_scores = get_fold_mse(train, kf)\n",
    "\n",
    "print('Mean validation MSE: {:.5f}'.format(np.mean(mse_scores)))\n",
    "print('MSE by fold: {}'.format(mse_scores))\n",
    "print('Overall validation MSE: {:.5f}'.format(np.mean(mse_scores) + np.std(mse_scores)))\n",
    "\n",
    "\"\"\"\n",
    "Mean validation MSE: 955.49186\n",
    "MSE by fold: [890.30336, 961.65797, 1014.51424]\n",
    "Overall validation MSE: 1006.38784\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetical features\n",
    "\n",
    "# Look at the initial RMSE\n",
    "print('RMSE before feature engineering:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the total area of the house\n",
    "train['TotalArea'] = train['TotalBsmtSF'] + train['FirstFlrSF'] + train['SecondFlrSF']\n",
    "\n",
    "# Look at the updated RMSE\n",
    "print('RMSE with total area:', get_kfold_rmse(train))\n",
    "\n",
    "\"\"\"\n",
    "RMSE before feature engineering: 36029.39\n",
    "RMSE with total area: 35073.2\n",
    "\"\"\"\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Look at the initial RMSE\n",
    "print('RMSE before feature engineering:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the total area of the house\n",
    "train['TotalArea'] = train['TotalBsmtSF'] + train['FirstFlrSF'] + train['SecondFlrSF']\n",
    "print('RMSE with total area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the area of the garden\n",
    "train['GardenArea'] = train['LotArea'] - train['FirstFlrSF']\n",
    "print('RMSE with garden area:', get_kfold_rmse(train))\n",
    "\n",
    "\"\"\"\n",
    "RMSE before feature engineering: 36029.39\n",
    "RMSE with total area: 35073.2\n",
    "RMSE with garden area: 34413.55\n",
    "\"\"\"\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Look at the initial RMSE\n",
    "print('RMSE before feature engineering:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the total area of the house\n",
    "train['TotalArea'] = train['TotalBsmtSF'] + train['FirstFlrSF'] + train['SecondFlrSF']\n",
    "print('RMSE with total area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the area of the garden\n",
    "train['GardenArea'] = train['LotArea'] - train['FirstFlrSF']\n",
    "print('RMSE with garden area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find total number of bathrooms\n",
    "train['TotalBath'] = train['FullBath'] + train['HalfBath']\n",
    "print('RMSE with number of bathrooms:', get_kfold_rmse(train))\n",
    "\n",
    "\"\"\"\n",
    "RMSE before feature engineering: 36029.39\n",
    "RMSE with total area: 35073.2\n",
    "RMSE with garden area: 34413.55\n",
    "RMSE with number of bathrooms: 34506.78\n",
    "\n",
    "You've created three new features. Here you see that house area improved the RMSE by almost $1,000. \n",
    "Adding garden area improved the RMSE by another $600. However, with the total number of bathrooms, \n",
    "the RMSE has increased. It means that you keep the new area features, but do not add \"TotalBath\" as a new feature. \n",
    "Let's now work with the datetime features!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date features\n",
    "\n",
    "# Concatenate train and test together\n",
    "taxi = pd.concat([train, test])\n",
    "\n",
    "# Convert pickup date to datetime object\n",
    "taxi['pickup_datetime'] = pd.to_datetime(taxi['pickup_datetime'])\n",
    "\n",
    "# Create a day of week feature\n",
    "taxi['dayofweek'] = taxi['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# Create an hour feature\n",
    "taxi['hour'] = taxi['pickup_datetime'].dt.hour\n",
    "\n",
    "# Split back into train and test\n",
    "new_train = taxi[taxi['id'].isin(train['id'])]\n",
    "new_test = taxi[taxi['id'].isin(test['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Create new features\n",
    "houses['RoofStyle_enc'] = le.fit_transform(houses['RoofStyle'])\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "# Look at new features\n",
    "print(houses[['RoofStyle', 'RoofStyle_enc', 'CentralAir', 'CentralAir_enc']].head())\n",
    "\n",
    "\"\"\"\n",
    "RoofStyle  RoofStyle_enc CentralAir  CentralAir_enc\n",
    "0     Gable              1          Y               1\n",
    "1     Gable              1          Y               1\n",
    "2     Gable              1          Y               1\n",
    "3     Gable              1          Y               1\n",
    "4     Gable              1          Y               1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding\n",
    "\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Look at feature distributions\n",
    "print(houses['RoofStyle'].value_counts(), '\\n')\n",
    "print(houses['CentralAir'].value_counts())\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Gable      2310\n",
    "Hip         551\n",
    "Gambrel      22\n",
    "Flat         20\n",
    "Mansard      11\n",
    "Shed          5\n",
    "Name: RoofStyle, dtype: int64 \n",
    "\n",
    "Y    2723\n",
    "N     196\n",
    "Name: CentralAir, dtype: int64\n",
    "\n",
    "--> CentralAir is binary\n",
    "\"\"\"\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encode binary 'CentralAir' feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Create One-Hot encoded features\n",
    "ohe = pd.get_dummies(houses['RoofStyle'], prefix='RoofStyle')\n",
    "\n",
    "# Concatenate OHE features to houses\n",
    "houses = pd.concat([houses, ohe], axis=1)\n",
    "\n",
    "# Look at OHE features\n",
    "print(houses[[col for col in houses.columns if 'RoofStyle' in col]].head(3))\n",
    "\n",
    "\"\"\"\n",
    "RoofStyle  RoofStyle_Flat  RoofStyle_Gable  RoofStyle_Gambrel  RoofStyle_Hip  RoofStyle_Mansard  RoofStyle_Shed\n",
    "0     Gable               0                1                  0              0                  0               0\n",
    "1     Gable               0                1                  0              0                  0               0\n",
    "2     Gable               0                1                  0              0                  0               0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean target encoding\n",
    "\n",
    "def test_mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Calculate global mean on the train data\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # Group by the categorical feature and calculate its properties\n",
    "    train_groups = train.groupby(categorical)\n",
    "    category_sum = train_groups[target].sum()\n",
    "    category_size = train_groups.size()\n",
    "    \n",
    "    # Calculate smoothed mean target statistics\n",
    "    train_statistics = (category_sum + global_mean * alpha) / (category_size + alpha)\n",
    "    \n",
    "    # Apply statistics to the test data and fill new categories\n",
    "    test_feature = test[categorical].map(train_statistics).fillna(global_mean)\n",
    "    return test_feature.values\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "def train_mean_target_encoding(train, target, categorical, alpha=5):\n",
    "    # Create 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "    train_feature = pd.Series(index=train.index)\n",
    "    \n",
    "    # For each folds split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "      \n",
    "        # Calculate out-of-fold statistics and apply to cv_test\n",
    "        cv_test_feature = test_mean_target_encoding(cv_train, cv_test, target, categorical, alpha)\n",
    "        \n",
    "        # Save new feature for this particular fold\n",
    "        train_feature.iloc[test_index] = cv_test_feature       \n",
    "    return train_feature.values\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "def mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "  \n",
    "    # Get the train feature\n",
    "    train_feature = train_mean_target_encoding(train, target, categorical, alpha)\n",
    "  \n",
    "    # Get the test feature\n",
    "    test_feature = test_mean_target_encoding(train, test, target, categorical, alpha)\n",
    "    \n",
    "    # Return new features to add to the model\n",
    "    return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross-validation\n",
    "\n",
    "# Create 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# For each folds split\n",
    "for train_index, test_index in kf.split(bryant_shots):\n",
    "    cv_train, cv_test = bryant_shots.iloc[train_index], bryant_shots.iloc[test_index]\n",
    "\n",
    "    # Create mean target encoded feature\n",
    "    cv_train['game_id_enc'], cv_test['game_id_enc'] = mean_target_encoding(train=cv_train,\n",
    "                                                                           test=cv_test,\n",
    "                                                                           target='shot_made_flag',\n",
    "                                                                           categorical='game_id',\n",
    "                                                                           alpha=5)\n",
    "    # Look at the encoding\n",
    "    print(cv_train[['game_id', 'shot_made_flag', 'game_id_enc']].sample(n=1))\n",
    "    \n",
    "\"\"\"\n",
    "           game_id  shot_made_flag  game_id_enc\n",
    "    7106  20500532             0.0     0.361914\n",
    "           game_id  shot_made_flag  game_id_enc\n",
    "    5084  20301100             0.0     0.568395\n",
    "           game_id  shot_made_flag  game_id_enc\n",
    "    6687  20500228             0.0      0.48131\n",
    "           game_id  shot_made_flag  game_id_enc\n",
    "    5046  20301075             0.0     0.252103\n",
    "           game_id  shot_made_flag  game_id_enc\n",
    "    4662  20300515             1.0     0.452637\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beyond binary classification\n",
    "\n",
    "# Create mean target encoded feature\n",
    "train['RoofStyle_enc'], test['RoofStyle_enc'] = mean_target_encoding(train=train,\n",
    "                                                                     test=test,\n",
    "                                                                     target='SalePrice',\n",
    "                                                                     categorical='RoofStyle',\n",
    "                                                                     alpha=10)\n",
    "\n",
    "# Look at the encoding\n",
    "print(test[['RoofStyle', 'RoofStyle_enc']].drop_duplicates())\n",
    "\n",
    "\"\"\"\n",
    "         RoofStyle  RoofStyle_enc\n",
    "    0        Gable  171565.947836\n",
    "    1          Hip  217594.645131\n",
    "    98     Gambrel  164152.950424\n",
    "    133       Flat  188703.563431\n",
    "    362    Mansard  180775.938759\n",
    "    1053      Shed  188267.663242\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing data\n",
    "\n",
    "# Read dataframe\n",
    "twosigma = pd.read_csv('twosigma_train.csv')\n",
    "\n",
    "# Find the number of missing values in each column\n",
    "print(twosigma.isna().sum())\n",
    "\n",
    "\"\"\"\n",
    "    id                 0\n",
    "    bathrooms          0\n",
    "    bedrooms           0\n",
    "    building_id       13 <---\n",
    "    latitude           0\n",
    "    longitude          0\n",
    "    manager_id         0\n",
    "    price             32 <---\n",
    "    interest_level     0\n",
    "    dtype: int64\n",
    "\"\"\"\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Read DataFrame\n",
    "twosigma = pd.read_csv('twosigma_train.csv')\n",
    "\n",
    "# Find the number of missing values in each column\n",
    "print(twosigma.isnull().sum())\n",
    "\n",
    "# Look at the columns with the missing values\n",
    "print(twosigma[['building_id', 'price']].head())\n",
    "\n",
    "\"\"\"\n",
    "    id                 0\n",
    "    bathrooms          0\n",
    "    bedrooms           0\n",
    "    building_id       13\n",
    "    latitude           0\n",
    "    longitude          0\n",
    "    manager_id         0\n",
    "    price             32\n",
    "    interest_level     0\n",
    "    dtype: int64\n",
    "                            building_id   price\n",
    "    0  53a5b119ba8f7b61d4e010512e0dfc85  3000.0\n",
    "    1  c5c8a357cba207596b04d1afd1e4f130  5465.0\n",
    "    2  c3ba40552e2120b0acfc3cb5730bb2aa  2850.0\n",
    "    3  28d9ad350afeaab8027513a3e52ac8d5  3275.0\n",
    "    4                               NaN  3350.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing data\n",
    "\n",
    "# Import SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create mean imputer\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Price imputation\n",
    "rental_listings[['price']] = mean_imputer.fit_transform(rental_listings[['price']])\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Import SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create constant imputer\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value='MISSING')\n",
    "\n",
    "# building_id imputation\n",
    "rental_listings[['building_id']] = constant_imputer.fit_transform(rental_listings[['building_id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate validation score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Calculate the mean fare_amount on the validation_train data\n",
    "naive_prediction = np.mean(validation_train['fare_amount'])\n",
    "\n",
    "# Assign naive prediction to all the holdout observations\n",
    "validation_test['pred'] = naive_prediction\n",
    "\n",
    "# Measure the local RMSE\n",
    "rmse = sqrt(mean_squared_error(validation_test['fare_amount'], validation_test['pred']))\n",
    "print('Validation RMSE for Baseline I model: {:.3f}'.format(rmse))\n",
    "\n",
    "\"\"\"Validation RMSE for Baseline I model: 9.986\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline based on the date\n",
    "\n",
    "# Get pickup hour from the pickup_datetime column\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "\n",
    "# Calculate average fare_amount grouped by pickup hour \n",
    "hour_groups = train.groupby('hour')['fare_amount'].mean()\n",
    "\n",
    "# Make predictions on the test set\n",
    "test['fare_amount'] = test.hour.map(hour_groups)\n",
    "\n",
    "# Write predictions\n",
    "test[['id','fare_amount']].to_csv('hour_mean_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline based on the gradient boosting\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Select only numeric features\n",
    "features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "            'dropoff_latitude', 'passenger_count', 'hour']\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train[features], train.fare_amount)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['fare_amount'] = rf.predict(test[features])\n",
    "\n",
    "# Write predictions\n",
    "test[['id','fare_amount']].to_csv('rf_sub.csv', index=False)\n",
    "\n",
    "\"\"\"\n",
    "This final baseline achieves the 1051st place on the Public Leaderboard which is slightly better than the Gradient Boosting \n",
    "from the video. So, now you know how to build fast and simple baseline models to validate your initial pipeline.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "\n",
    "# Possible max depth values\n",
    "max_depth_grid = [3, 6, 9, 12, 15]\n",
    "results = {}\n",
    "\n",
    "# For each value in the grid\n",
    "for max_depth_candidate in max_depth_grid:\n",
    "    # Specify parameters for the model\n",
    "    params = {'max_depth': max_depth_candidate}\n",
    "\n",
    "    # Calculate validation score for a particular hyperparameter\n",
    "    validation_score = get_cv_score(train, params)\n",
    "\n",
    "    # Save the results for each max depth value\n",
    "    results[max_depth_candidate] = validation_score   \n",
    "print(results)\n",
    "\n",
    "\"\"\"\n",
    "{3: 6.50509, 6: 6.52138, 9: 6.64181, 12: 6.8819, 15: 6.99156}\n",
    "We have a validation score for each value in the grid. It's clear that the optimal max depth value is located \n",
    "somewhere between 3 and 6. The next step could be to use a smaller grid, for example [3, 4, 5, 6] and \n",
    "repeat the same process. Moving from larger to smaller grids allows us to find the most optimal values. \n",
    "Keep going to try optimizing 2 hyperparameters simultaneously!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D grid search\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Hyperparameter grids\n",
    "max_depth_grid = [3, 5, 7]\n",
    "subsample_grid = [0.8, 0.9, 1.0]\n",
    "results = {}\n",
    "\n",
    "# For each couple in the grid\n",
    "for max_depth_candidate, subsample_candidate in itertools.product(max_depth_grid, subsample_grid):\n",
    "    params = {'max_depth': max_depth_candidate,\n",
    "              'subsample': subsample_candidate}\n",
    "    validation_score = get_cv_score(train, params)\n",
    "    # Save the results for each couple\n",
    "    results[(max_depth_candidate, subsample_candidate)] = validation_score   \n",
    "print(results)\n",
    "\n",
    "\"\"\"\n",
    "{(3, 0.8): 6.33917, (3, 0.9): 6.43642, (3, 1.0): 6.50509, (5, 0.8): 6.26977, (5, 0.9): 6.35116, (5, 1.0): 6.45468, (7, 0.8): 6.1635, (7, 0.9): 6.34018, (7, 1.0): 6.48436}\n",
    "You can see that tuning multiple hyperparameters simultaneously achieves better results. \n",
    "In the previous exercise, tuning only the max_depth parameter gave the best RMSE of $6.50. \n",
    "With max_depth equal to 7 and subsample equal to 0.8, the best RMSE is now $6.16. \n",
    "However, do not spend too much time on the hyperparameter tuning at the beginning of the competition! \n",
    "Another approach that almost always improves your solution is model ensembling. Go on for it!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model blending\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb = GradientBoostingRegressor().fit(train[features], train.fare_amount)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor().fit(train[features], train.fare_amount)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['gb_pred'] = gb.predict(test[features])\n",
    "test['rf_pred'] = rf.predict(test[features])\n",
    "\n",
    "# Find mean of model predictions\n",
    "test['blend'] = (test['gb_pred'] + test['rf_pred']) / 2\n",
    "print(test[['gb_pred', 'rf_pred', 'blend']].head(3))\n",
    "\n",
    "\"\"\"\n",
    "        gb_pred  rf_pred     blend\n",
    "    0  9.661374     9.00  9.330687\n",
    "    1  9.304288     8.45  8.877144\n",
    "    2  5.795140     5.11  5.452570\n",
    "    \n",
    "Blending allows you to get additional score improvements almost for free just by averaging multiple models predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model stacking I\n",
    "\n",
    "\"\"\"\n",
    "Split train data into two parts\n",
    "Train multiple models on Part 1\n",
    "Make predictions on Part 2\n",
    "Make predictions on the test data\n",
    "Train a new model on Part 2 using predictions as features\n",
    "Make predictions on the test data using the 2nd level model\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Split train data into two parts\n",
    "part_1, part_2 = train_test_split(train, test_size=0.5, random_state=123)\n",
    "\n",
    "# Train a Gradient Boosting model on Part 1\n",
    "gb = GradientBoostingRegressor().fit(part_1[features], part_1.fare_amount)\n",
    "\n",
    "# Train a Random Forest model on Part 1\n",
    "rf = RandomForestRegressor().fit(part_1[features], part_1.fare_amount)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Make predictions on the Part 2 data\n",
    "part_2['gb_pred'] = gb.predict(part_2[features])\n",
    "part_2['rf_pred'] = rf.predict(part_2[features])\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['gb_pred'] = gb.predict(test[features])\n",
    "test['rf_pred'] = rf.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model stacking II\n",
    "\n",
    "\"\"\"\n",
    "Split train data into two parts\n",
    "Train multiple models on Part 1\n",
    "Make predictions on Part 2\n",
    "Make predictions on the test data\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression model without the intercept\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# Train 2nd level model on the Part 2 data\n",
    "lr.fit(part_2[['gb_pred', 'rf_pred']], part_2.fare_amount)\n",
    "\n",
    "# Make stacking predictions on the test data\n",
    "test['stacking'] = lr.predict(test[['gb_pred', 'rf_pred']])\n",
    "\n",
    "# Look at the model coefficients\n",
    "print(lr.coef_)\n",
    "\n",
    "\"\"\"[0.72504358 0.27647395]\n",
    "\n",
    " Usually, the 2nd level model is some simple model like Linear or Logistic Regressions. \n",
    " Also, note that you were not using intercept in the Linear Regression just to combine pure model predictions. \n",
    " Looking at the coefficients, it's clear that 2nd level model has more trust to the Gradient Boosting: \n",
    " 0.7 versus 0.3 for the Random Forest model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Kaggle forum ideas\n",
    "\n",
    "# Suggestion 1: the passenger_count feature is useless. Let's see! Drop this feature and compare the scores.\n",
    "\n",
    "# Drop passenger_count column\n",
    "new_train_1 = train.drop('passenger_count', axis=1)\n",
    "\n",
    "# Compare validation scores\n",
    "initial_score = get_cv_score(train)\n",
    "new_score = get_cv_score(new_train_1)\n",
    "\n",
    "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# This first suggestion worked. Suggestion 2: Sum of pickup_latitude and distance_km is a good feature. Let's try it!\n",
    "\n",
    "# Create copy of the initial train DataFrame\n",
    "new_train_2 = train.copy()\n",
    "\n",
    "# Find sum of pickup latitude and ride distance\n",
    "new_train_2['weird_feature'] = new_train_2['pickup_latitude'] + new_train_2['distance_km']\n",
    "\n",
    "# Compare validation scores\n",
    "initial_score = get_cv_score(train)\n",
    "new_score = get_cv_score(new_train_2)\n",
    "\n",
    "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))\n",
    "\n",
    "\"\"\"\n",
    "Be aware that not all the ideas shared publicly could work for you! In this particular case, \n",
    "dropping the \"passenger_count\" feature helped, while finding the sum of pickup latitude and ride distance did not. \n",
    "The last action you perform in any Kaggle competition is selecting final submissions. Go on to practice it!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select final submissions\n",
    "The last action in every competition is selecting final submissions. Your goal is to select 2 final submissions based on the local validation and Public Leaderboard scores. Suppose that the competition metric is RMSE (the lower the metric the better). Keep up with a selection strategy we've discussed in the slides:\n",
    "\n",
    "Local validation: 1.25; Leaderboard: 1.35.\n",
    "Local validation: 1.32; Leaderboard: 1.39.\n",
    "Local validation: 1.10; Leaderboard: 1.29.\n",
    "Local validation: 1.17; Leaderboard: 1.25.\n",
    "Local validation: 1.21; Leaderboard: 1.32.\n",
    "\n",
    "--> Local validation: 1.10; Leaderboard: 1.29.\n",
    "Local validation: 1.17; Leaderboard: 1.25.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
