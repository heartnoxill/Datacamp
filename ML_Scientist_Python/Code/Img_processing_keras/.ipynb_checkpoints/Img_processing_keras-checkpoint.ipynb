{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing With Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images as data: visualizations\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "data = plt.imread('bricks.png')\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images as data: changing images\n",
    "\n",
    "# Set the red channel in this part of the image to 1\n",
    "data[0:10,0:10,0] = 1\n",
    "\n",
    "# Set the green channel in this part of the image to 0\n",
    "data[0:10,0:10,1] = 0\n",
    "\n",
    "# Set the blue channel in this part of the image to 0\n",
    "data[0:10,0:10,2] = 0\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using one-hot encoding to represent images\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 3\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"shirt\", \"dress\", \"shoe\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels = np.zeros((len(labels), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(labels)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories == labels[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating a classifier\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "number_correct = (test_labels * predictions).sum()\n",
    "print(number_correct)\n",
    "\n",
    "# Calculate the proportion of correct predictions\n",
    "proportion_correct = (number_correct / len(predictions))\n",
    "print(proportion_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a neural network\n",
    "\n",
    "# Imports components from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initializes a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(Dense(10, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Second layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a neural network\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "           loss='categorical_crossentropy', \n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a neural network model to clothing data\n",
    "\n",
    "# Reshape the data to two-dimensional array\n",
    "train_data = train_data.reshape((50, 784))\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_data, train_labels, validation_split=0.2, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for neural network evaluation\n",
    "\n",
    "# Reshape test data\n",
    "test_data = test_data.reshape((10, 784))\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One dimensional convolutions\n",
    "\n",
    "array = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "kernel = np.array([1, -1, 0])\n",
    "conv = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Output array\n",
    "for ii in range(8):\n",
    "    conv[ii] = (kernel * array[ii:ii+3]).sum()\n",
    "\n",
    "# Print conv\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image convolutions\n",
    "\n",
    "kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n",
    "result = np.zeros(im.shape)\n",
    "\n",
    "# Output array\n",
    "for ii in range(im.shape[0] - 3):\n",
    "    for jj in range(im.shape[1] - 3):\n",
    "        result[ii, jj] = (im[ii:ii+3, jj:jj+3] * kernel).sum()\n",
    "\n",
    "# Print result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining image convolution kernels\n",
    "\n",
    "# Define a kernel that finds horizontal lines in images.\n",
    "kernel = np.array([[-1, -1, -1], \n",
    "                   [1, 1, 1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "# Define a kernel that finds a light spot surrounded by dark pixels.\n",
    "kernel = np.array([[-1, -1, -1], \n",
    "                   [-1, 1, -1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "# Define a kernel that finds a dark spot surrounded by bright pixels.\n",
    "kernel = np.array([[1, 1, 1], \n",
    "                   [1, -1, 1],\n",
    "                   [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional network for image classification\n",
    "\n",
    "# Import the necessary components from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "# Initialize the model object\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "               input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Flatten the output of the convolutional layer\n",
    "model.add(Flatten())\n",
    "# Add an output layer for the 3 categories\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a CNN to classify clothing types\n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on a training set\n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating a CNN with test data\n",
    "\n",
    "# Evaluate the model on separate test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding to a CNN\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1), \n",
    "                 padding='same'))\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add strides to a convolutional network\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "              input_shape=(img_rows, img_cols, 1), \n",
    "              strides=2))\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\"\"\"\n",
    "With strides set to 2, the network skips every other pixel.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the size of convolutional layer output\n",
    "Zero padding and strides affect the size of the output of a convolution.\n",
    "\n",
    "What is the size of the output for an input of size 256 by 256, with a kernel of size 4 by 4, padding of 1 and strides of 2?\n",
    "\n",
    "--> 128\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Deeper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a deep learning network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer (15 units)\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add another convolutional layer (5 units)\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a deep CNN to classify clothing images\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to training data \n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is special about a deep network?\n",
    "Networks with more convolution layers are called \"deep\" networks, and they may have more power to fit complex data, because of their ability to create hierarchical representations of the data that they fit.\n",
    "\n",
    "What is a major difference between a deep CNN and a CNN with only one convolutional layer?\n",
    "\n",
    "--> A deep network requires more data and more computation to fit.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How many parameters in a CNN?\n",
    "We need to know how many parameters a CNN has, so we can adjust the model architecture, \n",
    "to reduce this number or shift parameters from one part of the network to another. \n",
    "How many parameters would a network have if its inputs are images with 28-by-28 pixels, \n",
    "there is one convolutional layer with 10 units kernels of 3-by-3 pixels, using zero padding \n",
    "(input has the same size as the output), and one densely connected layer with 2 units?\n",
    "\n",
    "--> 15,782\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many parameters in a deep CNN?\n",
    "\n",
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu', \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Summarize the model \n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_1 (Conv2D)            (None, 27, 27, 10)        50        \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 26, 26, 10)        410       \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 6760)              0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 3)                 20283     \n",
    "=================================================================\n",
    "Total params: 20,743\n",
    "Trainable params: 20,743\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "This model has 20,743 parameters!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own pooling operation\n",
    "\n",
    "# Result placeholder\n",
    "result = np.zeros((im.shape[0]//2, im.shape[1]//2))\n",
    "\n",
    "# Pooling operation\n",
    "for ii in range(result.shape[0]):\n",
    "    for jj in range(result.shape[1]):\n",
    "        result[ii, jj] = np.max(im[ii*2:ii*2+2, jj*2:jj*2+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras pooling layers\n",
    "\n",
    "\"\"\"\n",
    "Keras implements a pooling operation as a layer that can be added to CNNs between other layers. In this exercise, you will construct a convolutional neural network similar to the one you have constructed before:\n",
    "\n",
    "Convolution => Convolution => Flatten => Dense\n",
    "\n",
    "However, you will also add a pooling layer. The architecture will add a single max-pooling layer between the convolutional layer and the dense layer with a pooling of 2x2:\n",
    "\n",
    "Convolution => Max pooling => Convolution => Flatten => Dense\n",
    "\"\"\"\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a pooling operation\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_1 (Conv2D)            (None, 27, 27, 15)        75        \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 15)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 12, 12, 5)         305       \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 720)               0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 3)                 2163      \n",
    "=================================================================\n",
    "Total params: 2,543\n",
    "Trainable params: 2,543\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a deep CNN with pooling to classify images\n",
    "\n",
    "\"\"\"\n",
    "Convolution => Max pooling => Convolution => Flatten => Dense\n",
    "\"\"\"\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(train_data, train_labels, epochs=3, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate on test data \n",
    "model.evaluate(test_data, test_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Improving Deep Convolutional Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the training object\n",
    "training = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Extract the history from the training object\n",
    "history = training.history\n",
    "\n",
    "# Plot the training loss \n",
    "plt.plot(history['loss'])\n",
    "# Plot the validation loss\n",
    "plt.plot(history['val_loss'])\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using stored weights to predict in a test set\n",
    "\n",
    "# Load the weights from file\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Predict from the first three images in the test data\n",
    "model.predict(test_data[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dropout to your network\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a dropout layer\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add batch normalization to your network\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a kernel from a trained network\n",
    "\n",
    "# Load the weights into the model\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Get the first convolutional layer from the model\n",
    "c1 = model.layers[0]\n",
    "\n",
    "# Get the weights of the first convolutional layer\n",
    "weights1 = c1.get_weights()\n",
    "\n",
    "# Pull out the first channel of the first kernel in the first layer\n",
    "kernel = weights1[0][...,0, 0]\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing kernel responses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convolve with the fourth image in test_data\n",
    "out = convolution(test_data[3, :, :, 0], kernel) # 3 = fourth image\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(out)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
