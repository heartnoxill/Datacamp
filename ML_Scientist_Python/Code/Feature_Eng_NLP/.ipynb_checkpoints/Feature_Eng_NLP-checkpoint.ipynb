{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic features and readability scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "\n",
    "# Print the features of df1\n",
    "print(df1.columns)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df1 = pd.get_dummies(df1, columns=['feature 5'])\n",
    "\n",
    "# Print the new features of df1\n",
    "print(df1.columns)\n",
    "\n",
    "# Print first five rows of df1\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character count of Russian tweets\n",
    "\n",
    "# Create a feature char_count\n",
    "tweets['char_count'] = tweets['content'].apply(len)\n",
    "\n",
    "# Print the average character count\n",
    "print(tweets['char_count'].mean())\n",
    "\n",
    "\"\"\"\n",
    "<script.py> output:\n",
    "    103.462\n",
    "    \n",
    "Notice that the average character count of these tweets is approximately 104, which is much higher than the overall \n",
    "average tweet length of around 40 characters. Depending on what you're working on, this may be something worth \n",
    "investigating into. For your information, there is research that indicates that fake news articles tend to \n",
    "have longer titles! Therefore, even extremely basic features such as character counts can prove to be very useful in \n",
    "certain applications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count of TED talks\n",
    "\n",
    "# Function that returns number of words in a string\n",
    "def count_words(string):\n",
    "\t# Split the string into words\n",
    "    words = string.split()\n",
    "    \n",
    "    # Return the number of words\n",
    "    return len(words)\n",
    "\n",
    "# Create a new feature word_count\n",
    "ted['word_count'] = ted['transcript'].apply(count_words)\n",
    "\n",
    "# Print the average word count of the talks\n",
    "print(ted['word_count'].mean())\n",
    "\n",
    "\"\"\"\n",
    "<script.py> output:\n",
    "    1987.1\n",
    "    \n",
    "You now know how to compute the number of words in a given piece of text. Also, notice that the average length \n",
    "of a talk is close to 2000 words. You can use the word_count feature to compute its correlation with other variables \n",
    "such as number of views, number of comments, etc. and derive extremely interesting insights about TED.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashtags and mentions in Russian tweets\n",
    "\n",
    "# Function that returns numner of hashtags in a string\n",
    "def count_hashtags(string):\n",
    "\t# Split the string into words\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words that are hashtags\n",
    "    hashtags = [word for word in words if word.startswith('#')]\n",
    "    \n",
    "    # Return number of hashtags\n",
    "    return(len(hashtags))\n",
    "\n",
    "# Create a feature hashtag_count and display distribution\n",
    "tweets['hashtag_count'] = tweets['content'].apply(count_hashtags)\n",
    "tweets['hashtag_count'].hist()\n",
    "plt.title('Hashtag count distribution')\n",
    "plt.show()\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "# Function that returns number of mentions in a string\n",
    "def count_mentions(string):\n",
    "\t# Split the string into words\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words that are mentions\n",
    "    mentions = [word for word in words if word.startswith('@')]\n",
    "    \n",
    "    # Return number of mentions\n",
    "    return(len(mentions))\n",
    "\n",
    "# Create a feature mention_count and display distribution\n",
    "tweets['mention_count'] = tweets['content'].apply(count_mentions)\n",
    "tweets['mention_count'].hist()\n",
    "plt.title('Mention count distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readability of 'The Myth of Sisyphus'\n",
    "\n",
    "# Import Textatistic\n",
    "from textatistic import Textatistic\n",
    "\n",
    "# Compute the readability scores \n",
    "readability_scores = Textatistic(sisyphus_essay).scores\n",
    "\n",
    "# Print the flesch reading ease score\n",
    "flesch = readability_scores['flesch_score']\n",
    "print(\"The Flesch Reading Ease is %.2f\" % (flesch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readability of various publications\n",
    "\n",
    "# Import Textatistic\n",
    "from textatistic import Textatistic\n",
    "\n",
    "# List of excerpts\n",
    "excerpts = [forbes, harvard_law, r_digest, time_kids]\n",
    "\n",
    "# Loop through excerpts and compute gunning fog index\n",
    "gunning_fog_scores = []\n",
    "for excerpt in excerpts:\n",
    "  readability_scores = Textatistic(excerpt).scores\n",
    "  gunning_fog = readability_scores['gunningfog_score']\n",
    "  gunning_fog_scores.append(gunning_fog)\n",
    "\n",
    "# Print the gunning fog indices\n",
    "print(gunning_fog_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing, POS tagging and NER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Identifying lemmas\n",
    "Identify the list of words from the choices which do not have the same lemma.\n",
    "\n",
    "Car, Bike, Truck, Bus\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the Gettysburg Address\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(gettysburg)\n",
    "\n",
    "# Generate the tokens\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the Gettysburg address\n",
    "\n",
    "# Print the gettysburg address\n",
    "print(gettysburg)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(gettysburg)\n",
    "\n",
    "# Generate lemmas\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Convert lemmas into a string\n",
    "print(' '.join(lemmas))\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "    Four score and seven years ago our fathers brought forth on this continent, a new nation, \n",
    "    conceived in Liberty, and dedicated to the proposition that all men are created equal. \n",
    "    Now we're engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, \n",
    "    can long endure. We're met on a great battlefield of that war. We've come to dedicate a portion of that field, \n",
    "    as a final resting place for those who here gave their lives that that nation might live. It's altogether fitting \n",
    "    and proper that we should do this. But, in a larger sense, we can't dedicate - we can not consecrate - we can not hallow \n",
    "    - this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add \n",
    "    or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. \n",
    "    It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so \n",
    "    nobly advanced. It's rather for us to be here dedicated to the great task remaining before us - that from these honored \n",
    "    dead we take increased devotion to that cause for which they gave the last full measure of devotion - that we here highly\n",
    "    resolve that these dead shall not have died in vain - that this nation, under God, shall have a new birth of freedom - \n",
    "    and that government of the people, by the people, for the people, shall not perish from the earth.\n",
    "\n",
    "Output:\n",
    "    four score and seven year ago -PRON- father bring forth on this continent , a new nation , conceive in liberty ,\n",
    "    and dedicate to the proposition that all man be create equal . now -PRON- be engage in a great civil war , \n",
    "    test whether that nation , or any nation so conceive and so dedicated , can long endure . -PRON- be meet on a great \n",
    "    battlefield of that war . -PRON- have come to dedicate a portion of that field , as a final resting place for those who \n",
    "    here give -PRON- life that that nation may live . -PRON- be altogether fitting and proper that -PRON- should do this . \n",
    "    but , in a large sense , -PRON- can not dedicate - -PRON- can not consecrate - -PRON- can not hallow - this ground . \n",
    "    the brave man , living and dead , who struggle here , have consecrate -PRON- , far above -PRON- poor power to add or \n",
    "    detract . the world will little note , nor long remember what -PRON- say here , but -PRON- can never forget what -PRON- \n",
    "    do here . -PRON- be for -PRON- the living , rather , to be dedicate here to the unfinished work which -PRON- who fight \n",
    "    here have thus far so nobly advanced . -PRON- be rather for -PRON- to be here dedicate to the great task remain before \n",
    "    -PRON- - that from these honor dead -PRON- take increase devotion to that because for which -PRON- give the last full \n",
    "    measure of devotion - that -PRON- here highly resolve that these dead shall not have die in vain - that this nation , \n",
    "    under god , shall have a new birth of freedom - and that government of the people , by the people , for the people , \n",
    "    shall not perish from the earth .\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning a blog post\n",
    "\n",
    "# Load model and create Doc object\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(blog)\n",
    "\n",
    "# Generate lemmatized tokens\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Remove stopwords and non-alphabetic tokens\n",
    "a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in stopwords]\n",
    "\n",
    "# Print string after text cleaning\n",
    "print(' '.join(a_lemmas))\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "Twenty-first-century politics has witnessed an alarming rise of populism in the U.S. and Europe. \n",
    "The first warning signs came with the UK Brexit Referendum vote in 2016 swinging in the way of Leave. \n",
    "This was followed by a stupendous victory by billionaire Donald Trump to become the 45th President of the United States \n",
    "in November 2016. Since then, Europe has seen a steady rise in populist and far-right parties that have capitalized on\n",
    "Europe’s Immigration Crisis to raise nationalist and anti-Europe sentiments. Some instances include Alternative \n",
    "for Germany (AfD) winning 12.6% of all seats and entering the Bundestag, thus upsetting Germany’s political order for \n",
    "the first time since the Second World War, the success of the Five Star Movement in Italy and the surge in popularity of \n",
    "neo-nazism and neo-fascism in countries such as Hungary, Czech Republic, Poland and Austria.\n",
    "\n",
    "Output:\n",
    "century politic witness alarming rise populism europe warning sign come uk brexit referendum vote \n",
    "swinging way leave follow stupendous victory billionaire donald trump president united states november \n",
    "europe steady rise populist far right party capitalize europe immigration crisis raise nationalist anti \n",
    "europe sentiment instance include alternative germany afd win seat enter bundestag upset germany political \n",
    "order time second world war success star movement italy surge popularity neo nazism neo fascism country hungary \n",
    "czech republic poland austria\n",
    "\n",
    "Note:\n",
    "Take a look at the cleaned text; it is lowercased and devoid of numbers, punctuations and commonly used stopwords. \n",
    "Also, note that the word U.S. was present in the original text. Since it had periods in between, our text cleaning \n",
    "process completely removed it. This may not be ideal behavior. It is always advisable to use your custom functions \n",
    "in place of isalpha() for more nuanced cases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning TED talks in a dataframe\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess(text):\n",
    "  \t# Create Doc object\n",
    "    doc = nlp(text, disable=['ner', 'parser'])\n",
    "    # Generate lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Remove stopwords and non-alphabetic characters\n",
    "    a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in stopwords]\n",
    "    \n",
    "    return ' '.join(a_lemmas)\n",
    "  \n",
    "# Apply preprocess to ted['transcript']\n",
    "ted['transcript'] = ted['transcript'].apply(preprocess)\n",
    "print(ted['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging in Lord of the Flies\n",
    "\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(lotf)\n",
    "\n",
    "# Generate tokens and pos tags\n",
    "pos = [(token.text, token.pos_) for token in doc]\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting nouns in a piece of text\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Returns number of proper nouns\n",
    "def proper_nouns(text, model=nlp):\n",
    "  \t# Create doc object\n",
    "    doc = model(text)\n",
    "    # Generate list of POS tags\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Return number of proper nouns\n",
    "    return pos.count('PROPN')\n",
    "\n",
    "print(proper_nouns(\"Abdul, Bill and Cathy went to the market to buy apples.\", nlp))\n",
    "\n",
    "\"\"\"<script.py> output:\n",
    "    3\"\"\"\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Returns number of other nouns\n",
    "def nouns(text, model=nlp):\n",
    "  \t# Create doc object\n",
    "    doc = model(text)\n",
    "    # Generate list of POS tags\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Return number of other nouns\n",
    "    return pos.count('NOUN')\n",
    "\n",
    "print(nouns(\"Abdul, Bill and Cathy went to the market to buy apples.\", nlp))\n",
    "\n",
    "\"\"\"<script.py> output:\n",
    "    2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun usage in fake news\n",
    "\n",
    "headlines['num_propn'] = headlines['title'].apply(proper_nouns)\n",
    "\n",
    "# Compute mean of proper nouns\n",
    "real_propn = headlines[headlines['label'] == 'REAL']['num_propn'].mean()\n",
    "fake_propn = headlines[headlines['label'] == 'FAKE']['num_propn'].mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Mean no. of proper nouns in real and fake headlines are %.2f and %.2f respectively\"%(real_propn, fake_propn))\n",
    "\n",
    "\"\"\"    Mean no. of proper nouns in real and fake headlines are 2.46 and 4.86 respectively\n",
    "\"\"\"\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "headlines['num_noun'] = headlines['title'].apply(nouns)\n",
    "\n",
    "# Compute mean of other nouns\n",
    "real_noun = headlines[headlines['label'] == 'REAL']['num_noun'].mean()\n",
    "fake_noun = headlines[headlines['label'] == 'FAKE']['num_noun'].mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Mean no. of other nouns in real and fake headlines are %.2f and %.2f respectively\"%(real_noun, fake_noun))\n",
    "\n",
    "\"\"\"    Mean no. of other nouns in real and fake headlines are 2.30 and 1.44 respectively\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named entities in a sentence\n",
    "\n",
    "# Load the required model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a Doc instance \n",
    "text = 'Sundar Pichai is the CEO of Google. Its headquarters is in Mountain View.'\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print all named entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "\"\"\"\n",
    "Sundar Pichai ORG\n",
    "    Google ORG\n",
    "    Mountain View GPE\n",
    "    \n",
    "Notice how the model correctly predicted the labels of Google and Mountain View but mislabeled Sundar Pichai as \n",
    "an organization. As discussed in the video, the predictions of the model depend strongly on the data it is trained on. \n",
    "It is possible to train spaCy models on your custom data. You will learn to do this in more advanced NLP courses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying people mentioned in a news article\n",
    "\n",
    "def find_persons(text):\n",
    "  # Create Doc object\n",
    "  doc = nlp(text)\n",
    "  \n",
    "  # Identify the persons\n",
    "  persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "  \n",
    "  # Return persons\n",
    "  return persons\n",
    "\n",
    "print(find_persons(tc))\n",
    "\n",
    "\"\"\"\n",
    "['Sheryl Sandberg', 'Mark Zuckerberg']\n",
    "\n",
    "The article was related to Facebook and our function correctly identified both the people mentioned. \n",
    "You can now see how NER could be used in a variety of applications. Publishers may use a technique like this to \n",
    "classify news articles by the people mentioned in them. A question answering system could also use something like \n",
    "this to answer questions such as 'Who are the people mentioned in this passage?'. With this, we come to an end of \n",
    "this chapter. In the next, we will learn how to conduct vectorization on documents.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Word vectors with a given vocabulary\n",
    "You have been given a corpus of documents and you have computed the vocabulary of the corpus to be the following: \n",
    "V: a, an, and, but, can, come, evening, forever, go, i, men, may, on, the, women\n",
    "\n",
    "Which of the following corresponds to the bag of words vector for the document \"men may come and men may go but i go \n",
    "on forever\"?\n",
    "\n",
    "(0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 2, 1, 0, 0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW model for movie taglines\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print the shape of bow_matrix\n",
    "print(bow_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing dimensionality and preprocessing\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_lem_matrix = vectorizer.fit_transform(lem_corpus)\n",
    "\n",
    "# Print the shape of bow_lem_matrix\n",
    "print(bow_lem_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping feature indices with feature names\n",
    "\n",
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert bow_matrix into a DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray())\n",
    "\n",
    "# Map the column names to vocabulary \n",
    "bow_df.columns = vectorizer.get_feature_names()\n",
    "\n",
    "# Print bow_df\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW vectors for movie reviews\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "\n",
    "# Fit and transform X_train\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Print shape of X_train_bow and X_test_bow\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)\n",
    "\n",
    "\"\"\"\n",
    " You now have a good idea of preprocessing text and transforming them into their bag-of-words representation \n",
    " using CountVectorizer. In this exercise, you have set the lowercase argument to True. However, note that this \n",
    " is the default value of lowercase and passing it explicitly is not necessary. Also, note that both X_train_bow \n",
    " and X_test_bow have 8158 features. There were words present in X_test that were not in X_train. CountVectorizer \n",
    " chose to ignore them in order to ensure that the dimensions of both sets remain the same.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the sentiment of a movie review\n",
    "\n",
    "# Create a MultinomialNB object\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf.score(X_test_bow, y_test)\n",
    "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
    "\n",
    "# Predict the sentiment of a negative review\n",
    "review = \"The movie was terrible. The music was underwhelming and the acting mediocre.\"\n",
    "prediction = clf.predict(vectorizer.transform([review]))[0]\n",
    "print(\"The sentiment predicted by the classifier is %i\" % (prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram models for movie tag lines\n",
    "\n",
    "# Generate n-grams upto n=1\n",
    "vectorizer_ng1 = CountVectorizer(ngram_range=(1,1))\n",
    "ng1 = vectorizer_ng1.fit_transform(corpus)\n",
    "\n",
    "# Generate n-grams upto n=2\n",
    "vectorizer_ng2 = CountVectorizer(ngram_range=(1,2))\n",
    "ng2 = vectorizer_ng2.fit_transform(corpus)\n",
    "\n",
    "# Generate n-grams upto n=3\n",
    "vectorizer_ng3 = CountVectorizer(ngram_range=(1, 3))\n",
    "ng3 = vectorizer_ng3.fit_transform(corpus)\n",
    "\n",
    "# Print the number of features for each model\n",
    "print(\"ng1, ng2 and ng3 have %i, %i and %i features respectively\" % (ng1.shape[1], ng2.shape[1], ng3.shape[1]))\n",
    "\n",
    "\"\"\"\n",
    "    ng1, ng2 and ng3 have 6614, 37100 and 76881 features respectively\n",
    "\n",
    " You now know how to generate n-gram models containing higher order n-grams. Notice that ng2 has over 37,000 features \n",
    " whereas ng3 has over 76,000 features. This is much greater than the 6,000 dimensions obtained for ng1. As the n-gram \n",
    " range increases, so does the number of features, leading to increased computational costs and a problem known as the \n",
    " curse of dimensionality.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher order n-grams for sentiment analysis\n",
    "\n",
    "# Define an instance of MultinomialNB \n",
    "clf_ng = MultinomialNB()\n",
    "\n",
    "# Fit the classifier \n",
    "clf_ng.fit(X_train_ng, y_train)\n",
    "\n",
    "# Measure the accuracy \n",
    "accuracy = clf_ng.score(X_test_ng, y_test)\n",
    "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
    "\n",
    "# Predict the sentiment of a negative review\n",
    "review = \"The movie was not good. The plot had several holes and the acting lacked panache.\"\n",
    "prediction = clf_ng.predict(ng_vectorizer.transform([review]))[0]\n",
    "print(\"The sentiment predicted by the classifier is %i\" % (prediction))\n",
    "\n",
    "\"\"\"\n",
    "The accuracy of the classifier on the test set is 0.758\n",
    "The sentiment predicted by the classifier is 0\n",
    "\n",
    "You're now adept at performing sentiment analysis using text. Notice how this classifier performs slightly \n",
    "better than the BoW version. Also, it succeeds at correctly identifying the sentiment of the mini-review as \n",
    "negative. In the next chapter, we will learn more complex methods of vectorizing textual data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing performance of n-gram models\n",
    "\n",
    "start_time = time.time()\n",
    "# Splitting the data into training and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(df['review'], df['sentiment'], test_size=0.5, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "# Generating ngrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "train_X = vectorizer.fit_transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)\n",
    "\n",
    "# Fit classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "# Print accuracy, time and number of dimensions\n",
    "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. The ngram representation had %i features.\" % (time.time() - start_time, clf.score(test_X, test_y), train_X.shape[1]))\n",
    "\n",
    "\"\"\"\n",
    "The program took 0.186 seconds to complete. The accuracy on the test set is 0.75. The ngram representation had 12347 features.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "start_time = time.time()\n",
    "# Splitting the data into training and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(df['review'], df['sentiment'], test_size=0.5, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "# Generating ngrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "train_X = vectorizer.fit_transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)\n",
    "\n",
    "# Fit classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "# Print accuracy, time and number of dimensions\n",
    "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. The ngram representation had %i features.\" % (time.time() - start_time, clf.score(test_X, test_y), train_X.shape[1]))\n",
    "\n",
    "\"\"\"\n",
    "The program took 2.320 seconds to complete. The accuracy on the test set is 0.77. The ngram representation had 178240 features.\n",
    "\n",
    "The program took around 0.2 seconds in the case of the unigram model and more than 10 times longer for the higher order\n",
    "n-gram model. The unigram model had over 12,000 features whereas the n-gram model for upto n=3 had over 178,000! \n",
    "Despite taking higher computation time and generating more features, the classifier only performs marginally better \n",
    "in the latter case, producing an accuracy of 77% in comparison to the 75% for the unigram model.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF and similarity scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tf-idf weight of commonly occurring words\n",
    "The word bottle occurs 5 times in a particular document D and also occurs in every document of the corpus. What is the tf-idf weight of bottle in D?\n",
    "\n",
    "0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf vectors for TED talks\n",
    "\n",
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(ted)\n",
    "\n",
    "# Print the shape of tfidf_matrix\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cosine similarity: https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "\n",
    "Range of cosine scores\n",
    "Which of the following is a possible cosine score for a pair of document vectors?\n",
    "\n",
    "0.86\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing dot product\n",
    "\n",
    "# Initialize numpy vectors\n",
    "A = np.array([1,3])\n",
    "B = np.array([-2,2])\n",
    "\n",
    "# Compute dot product\n",
    "dot_prod = np.dot(A, B)\n",
    "\n",
    "# Print dot product\n",
    "print(dot_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity matrix of a corpus\n",
    "\n",
    "# Initialize an instance of tf-idf Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate the tf-idf vectors for the corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Compute and print the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing linear_kernel and cosine_similarity\n",
    "\n",
    "# Record start time\n",
    "start = time.time()\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Print cosine similarity matrix\n",
    "print(cosine_sim)\n",
    "\n",
    "# Print time taken\n",
    "print(\"Time taken: %s seconds\" %(time.time() - start))\n",
    "\n",
    "\"\"\"\n",
    "[[1.         0.         0.         ... 0.         0.         0.        ]\n",
    "     [0.         1.         0.         ... 0.         0.         0.        ]\n",
    "     [0.         0.         1.         ... 0.         0.01418221 0.        ]\n",
    "     ...\n",
    "     [0.         0.         0.         ... 1.         0.01589009 0.        ]\n",
    "     [0.         0.         0.01418221 ... 0.01589009 1.         0.        ]\n",
    "     [0.         0.         0.         ... 0.         0.         1.        ]]\n",
    "    Time taken: 0.32955265045166016 seconds\n",
    "\"\"\"\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "# Record start time\n",
    "start = time.time()\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Print cosine similarity matrix\n",
    "print(cosine_sim)\n",
    "\n",
    "# Print time taken\n",
    "print(\"Time taken: %s seconds\" %(time.time() - start))\n",
    "\n",
    "\"\"\"\n",
    "[[1.         0.         0.         ... 0.         0.         0.        ]\n",
    "     [0.         1.         0.         ... 0.         0.         0.        ]\n",
    "     [0.         0.         1.         ... 0.         0.01418221 0.        ]\n",
    "     ...\n",
    "     [0.         0.         0.         ... 1.         0.01589009 0.        ]\n",
    "     [0.         0.         0.01418221 ... 0.01589009 1.         0.        ]\n",
    "     [0.         0.         0.         ... 0.         0.         1.        ]]\n",
    "    Time taken: 0.32399821281433105 seconds\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Notice how both linear_kernel and cosine_similarity produced the same result. However, linear_kernel took a \n",
    "smaller amount of time to execute. When you're working with a very large amount of data and your vectors are \n",
    "in the tf-idf representation, it is good practice to default to linear_kernel to improve performance. \n",
    "(NOTE: In case, you see linear_kernel taking more time, it's because the dataset we're dealing with is extremely \n",
    "small and Python's time module is incapable of capture such minute time differences accurately)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot recommendation engine\n",
    "\n",
    "# Initialize the TfidfVectorizer \n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Construct the TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(movie_plots)\n",
    "\n",
    "# Generate the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    " \n",
    "# Generate recommendations \n",
    "print(get_recommendations('The Dark Knight Rises', cosine_sim, indices))\n",
    "\n",
    "\"\"\"\n",
    "1                              Batman Forever\n",
    "    2                                      Batman\n",
    "    3                              Batman Returns\n",
    "    8                  Batman: Under the Red Hood\n",
    "    9                            Batman: Year One\n",
    "    10    Batman: The Dark Knight Returns, Part 1\n",
    "    11    Batman: The Dark Knight Returns, Part 2\n",
    "    5                Batman: Mask of the Phantasm\n",
    "    7                               Batman Begins\n",
    "    4                              Batman & Robin\n",
    "    Name: title, dtype: object\n",
    "    \n",
    "You've just built your very first recommendation system. Notice how the recommender correctly identifies 'The Dark Knight Rises'\n",
    "as a Batman movie and recommends other Batman movies as a result. This sytem is, of course, very primitive and there are a \n",
    "host of ways in which it could be improved. One method would be to look at the cast, crew and genre in addition to the plot\n",
    "to generate recommendations. We will not be covering this in this course but you have all the tools necessary \n",
    "to accomplish this. Do give it a try!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The recommender function\n",
    "\n",
    "# Generate mapping between titles and index\n",
    "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()\n",
    "\n",
    "def get_recommendations(title, cosine_sim, indices):\n",
    "    # Get index of title that matches title\n",
    "    idx = indices[title]\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Get the scores for 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    # Return the top 10 most similar movies\n",
    "    return metadata['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TED talk recommender\n",
    "\n",
    "# Initialize the TfidfVectorizer \n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Construct the TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(transcripts)\n",
    "\n",
    "# Generate the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    " \n",
    "# Generate recommendations \n",
    "print(get_recommendations('5 ways to kill your dreams', cosine_sim, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating word vectors\n",
    "\n",
    "# Create the doc object\n",
    "doc = nlp(sent)\n",
    "\n",
    "# Compute pairwise similarity scores\n",
    "for token1 in doc:\n",
    "  for token2 in doc:\n",
    "    print(token1.text, token2.text, token1.similarity(token2))\n",
    "    \n",
    "\"\"\"\n",
    "I I 1.0\n",
    "    I like 0.023032807\n",
    "    I apples 0.10175116\n",
    "    I and 0.047492094\n",
    "    I oranges 0.10894456\n",
    "    like I 0.023032807\n",
    "    like like 1.0\n",
    "    like apples 0.015370452\n",
    "    like and 0.189293\n",
    "    like oranges 0.021943133\n",
    "    apples I 0.10175116\n",
    "    apples like 0.015370452\n",
    "    apples apples 1.0\n",
    "    apples and -0.17736834\n",
    "    apples oranges 0.6315578\n",
    "    and I 0.047492094\n",
    "    and like 0.189293\n",
    "    and apples -0.17736834\n",
    "    and and 1.0\n",
    "    and oranges 0.018627528\n",
    "    oranges I 0.10894456\n",
    "    oranges like 0.021943133\n",
    "    oranges apples 0.6315578\n",
    "    oranges and 0.018627528\n",
    "    oranges oranges 1.0\n",
    "    \n",
    "Notice how the words 'apples' and 'oranges' have the highest pairwaise similarity score. This is expected as \n",
    "they are both fruits and are more related to each other than any other pair of words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bc6cb215387e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create Doc objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmother_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mhopes_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhopes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mhey_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Computing similarity of Pink Floyd songs\n",
    "\n",
    "# Create Doc objects\n",
    "mother_doc = nlp(mother)\n",
    "hopes_doc = nlp(hopes)\n",
    "hey_doc = nlp(hey)\n",
    "\n",
    "# Print similarity between mother and hopes\n",
    "print(mother_doc.similarity(hopes_doc))\n",
    "\n",
    "# Print similarity between mother and hey\n",
    "print(mother_doc.similarity(hey_doc))\n",
    "\n",
    "\"\"\"\n",
    "<script.py> output:\n",
    "    0.6006234924640204\n",
    "    0.9135920924498578\n",
    "    \n",
    "Notice that 'Mother' and 'Hey You' have a similarity score of 0.9 whereas 'Mother' and 'High Hopes' \n",
    "has a score of only 0.6. This is probably because 'Mother' and 'Hey You' were both songs from the same album \n",
    "'The Wall' and were penned by Roger Waters. On the other hand, 'High Hopes' was a part of the album 'Division Bell'\n",
    "with lyrics by David Gilmour and his wife, Penny Samson. Treat yourself by listening to these songs. \n",
    "They're some of the best!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
